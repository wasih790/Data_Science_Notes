{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6899ad425e03acd4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Phase 3 Code Challenge\n",
    "\n",
    "This assessment is designed to test your understanding of Module 3 material. It covers:\n",
    "\n",
    "* Gradient Descent\n",
    "* Logistic Regression\n",
    "* Classification Metrics\n",
    "* Decision Trees\n",
    "\n",
    "_Read the instructions carefully_. You will be asked both to write code and to answer short answer questions.\n",
    "\n",
    "## Code Tests\n",
    "\n",
    "We have provided some code tests for you to run to check that your work meets the item specifications. Passing these tests does not necessarily mean that you have gotten the item correct - there are additional hidden tests. However, if any of the tests do not pass, this tells you that your code is incorrect and needs changes to meet the specification. To determine what the issue is, read the comments in the code test cells, the error message you receive, and the item instructions.\n",
    "\n",
    "## Short Answer Questions \n",
    "\n",
    "For the short answer questions...\n",
    "\n",
    "* _Use your own words_. It is OK to refer to outside resources when crafting your response, but _do not copy text from another source_.\n",
    "\n",
    "* _Communicate clearly_. We are not grading your writing skills, but you can only receive full credit if your teacher is able to fully understand your response. \n",
    "\n",
    "* _Be concise_. You should be able to answer most short answer questions in a sentence or two. Writing unnecessarily long answers increases the risk of you being unclear or saying something incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c2a2bae912a0e147",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes to import the necessary libraries\n",
    "\n",
    "from numbers import Number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-962cbb6c01caf427",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "## Part 1: Gradient Descent [Suggested Time: 20 min]\n",
    "---\n",
    "In this part, you will describe how gradient descent works to calculate a parameter estimate. Below is an image of a best fit line from a linear regression model using TV advertising spending to predict product sales.\n",
    "\n",
    "![best fit line](https://raw.githubusercontent.com/learn-co-curriculum/dsc-cc-images/main/phase_3/best_fit_line.png)\n",
    "\n",
    "This best fit line can be described by the equation $y = mx + b$. Below is the RSS cost curve associated with the slope parameter $m$:\n",
    "\n",
    "![cost curve](https://raw.githubusercontent.com/learn-co-curriculum/dsc-cc-images/main/phase_3/cost_curve.png)\n",
    "\n",
    "where RSS is the residual sum of squares: $RSS = \\sum_{i=1}^n(y_i - (mx_i + b))^2$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f5be777299f6d5be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.1) Short Answer: Explain how the RSS curve above could be used to find an optimal value for the slope parameter $m$. \n",
    "\n",
    "Your answer should provide a one sentence summary, not every step of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your answer here\n",
    "\n",
    "- Plot shows the error (RSS) on the y-axis and the slope of the model on the x-axis, its show witch slope has the lowest amount of error. For each point Graident descent find the parital derivative, and when the derivative is closet to 0, that is the optimal value for slope parameter.\n",
    "- From this graph you can see that it arrived between 0.04 and 0.06 for the optimal coefficient value, since it's around that point that the error term (RSS) is smallest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-04569212f96246b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Below is a visualization showing the iterations of a gradient descent algorithm applied the RSS curve. Each yellow marker represents an estimate, and the lines between markers represent the steps taken between estimates in each iteration. Numeric labels identify the iteration numbers.\n",
    "\n",
    "![gradient descent](https://raw.githubusercontent.com/learn-co-curriculum/dsc-cc-images/main/phase_3/gd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8f8743b8bb5caf43",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2) Short Answer: Explain why the distances between markers get smaller over successive iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your answer here\n",
    "\n",
    "\n",
    "- Becuase of the step size and learning rate\n",
    "- Step size captures the amount to change the coefficient as it tries to minimize the error term\n",
    "- Learning rate determines how large those steps are to start\n",
    "- Gradient descent, take 1 point see the RSS, and it keep going down to check if the RSS is smaller, step size help with going faster down. \n",
    "- step size = learning rate * slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f38904edac3e34ba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.3) Short Answer: What would be the effect of decreasing the learning rate for this application of gradient descent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your answer here\n",
    "\n",
    "- a smaller step size would be the effect of a smaller learning rate\n",
    "- step size = learning rate * slope\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-58cbc9e518eda9a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "## Part 2: Logistic Regression [Suggested Time: 15 min]\n",
    "---\n",
    "In this part, you will answer general questions about logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a5eed21ce4450ee7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.1) Short Answer: Provide one reason why logistic regression is better than linear regression for modeling a binary target/outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your answer here\n",
    "\n",
    "- Logistic Regression is for classification problems (categorical targets), linear is not used for classification. Linaer is used to a continous varaible\n",
    "- Linear regression predicts a continuous target, and is not bound between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fc85e3d7f84c78d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.2) Short Answer: Compare logistic regression to another classification model of your choice (e.g. KNN, Decision Tree, etc.). What is one advantage and one disadvantage logistic regression has when compared with the other model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your answer here\n",
    "### KNN vs. Logistics Regression\n",
    "\n",
    "- Interpretable results: Logistic regression provides interpretable results by estimating the probabilities of class membership based on the input features\n",
    "\n",
    "- KNN supports non-linear solutions where LR supports only linear solutions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0d9d765be95e6cc0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "## Part 3: Classification Metrics [Suggested Time: 20 min]\n",
    "---\n",
    "In this part, you will make sense of classification metrics produced by various classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d2ad4f31491e50b6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The confusion matrix below represents the predictions generated by a classisification model on a small testing dataset.\n",
    "\n",
    "![cnf matrix](https://raw.githubusercontent.com/learn-co-curriculum/dsc-cc-images/main/phase_3/cnf_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e4b5c09376d185ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.1) Create a numeric variable `precision` containing the precision of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "# CodeGrade step3.1\n",
    "# Replace None with appropriate code\n",
    "\n",
    "precision = 30/(30+4)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This test confirms that you have created a numeric variable named precision\n",
    "\n",
    "assert isinstance(precision, Number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-09e2fa2bf91d1c95",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.2) Create a numeric variable `f1score` containing the F-1 score of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6bce80c352c6ad99",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857142857143\n",
      "0.7894736842105262\n"
     ]
    }
   ],
   "source": [
    "# CodeGrade step3.2\n",
    "# Replace None with appropriate code\n",
    "recall = 30 / (30+12)\n",
    "print(recall)\n",
    "f1score =  2 * precision * recall / (precision + recall)\n",
    "print(f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This test confirms that you have created a numeric variable named f1score\n",
    "\n",
    "assert isinstance(f1score, Number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8c9611b7378f9cd8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The ROC curves below were calculated for three different models applied to one dataset.\n",
    "\n",
    "1. Only Age was used as a feature in the model\n",
    "2. Only Estimated Salary was used as a feature in the model\n",
    "3. All features were used in the model\n",
    "\n",
    "![roc](https://raw.githubusercontent.com/learn-co-curriculum/dsc-cc-images/main/phase_3/many_roc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6b2fccd135d7bd12",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.3) Short Answer: Identify the best ROC curve in the above graph and explain why it is the best. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your answer here\n",
    "- the best Roc curve is the model with all features, because it is the only with reduce FP rate and high TP rates compared to other models. The best performace model should hug the upper left conner of the graph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9a2e4b682abfc6ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the following cells to load a sample dataset, run a classification model on it, and perform some EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9e7642482fd78eb5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier has an accuracy score of 0.956.\n"
     ]
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "# Include relevant imports\n",
    "import pickle, sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\n",
    "\n",
    "network_df = pickle.load(open('sample_network_data.pkl', 'rb'))\n",
    "\n",
    "# partion features and target \n",
    "X = network_df.drop('Purchased', axis=1)\n",
    "y = network_df['Purchased']\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2019)\n",
    "\n",
    "# scale features\n",
    "scale = StandardScaler()\n",
    "scale.fit(X_train)\n",
    "X_train = scale.transform(X_train)\n",
    "X_test = scale.transform(X_test)\n",
    "\n",
    "# build classifier\n",
    "model = LogisticRegression(C=1e5, solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# get the accuracy score\n",
    "print(f'The classifier has an accuracy score of {round(accuracy_score(y_test, y_test_pred), 3)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e21cfbd2172b791a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    257\n",
       "1     13\n",
       "Name: Purchased, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.951852\n",
       "1    0.048148\n",
       "Name: Purchased, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b3dee6c580108f26",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.4) Short Answer: Explain how the distribution of `y` shown above could explain the high accuracy score of the classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your answer here\n",
    " - Imbalanced target - 95% of data is in class 0\n",
    "- Predicting only our majority class, 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-15288334b184b850",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.5) Short Answer: What is one method you could use to improve your model to address the issue discovered in Question 3.4?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your answer here\n",
    "\n",
    "- Target is imbalanced\n",
    "- Oversampling, synthetic oversampling (SMOTE), set `class_weight`\n",
    "- Note that undersampling doesn't make sense here, since our dataset is so small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6bdb41dda25eb6b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "## Part 4: Decision Trees [Suggested Time: 20 min]\n",
    "---\n",
    "In this part, you will use decision trees to fit a classification model to a wine dataset. The data contain the results of a chemical analysis of wines grown in one region in Italy using three different cultivars (grape types). There are thirteen features from the measurements taken, and the wines are classified by cultivar in the `target` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-15de0bc4280a2aac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "# Relevant imports \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load the data \n",
    "wine = load_wine()\n",
    "X, y = load_wine(return_X_y=True)\n",
    "X = pd.DataFrame(X, columns=wine.feature_names)\n",
    "y = pd.Series(y)\n",
    "y.name = 'target'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-561128e9ee6b0299",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 4.1) Use `train_test_split()` to evenly split `X` and `y` data between training sets (`X_train` and `y_train`) and test sets (`X_test` and `y_test`), with `random_state=1`.\n",
    "\n",
    "Do not alter `X` or `y` before performing the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0be055a675c0a674",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CodeGrade step4.1\n",
    "# Replace None with appropriate code\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 1, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These tests confirm that you have created DataFrames named X_train, X_test and Series named y_train, and y_test\n",
    "\n",
    "assert type(X_train) == pd.DataFrame\n",
    "assert type(X_test) == pd.DataFrame\n",
    "assert type(y_train) == pd.Series\n",
    "assert type(y_test) == pd.Series\n",
    "\n",
    "# These tests confirm that you have split the data evenly between train and test sets\n",
    "\n",
    "assert X_train.shape[0] == X_test.shape[0]\n",
    "assert y_train.shape[0] == y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eac2fc7be9725bf0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 4.2) Create an untuned decision tree classifier `wine_dt` and fit it using `X_train` and `y_train`, with `random_state=1`. \n",
    "\n",
    "Use parameter defaults for your classifier. You must use the Scikit-learn DecisionTreeClassifier (docs [here](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-28bca1a3b0de0dd8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CodeGrade step4.2\n",
    "# Replace None with appropriate code\n",
    "\n",
    "wine_dt = DecisionTreeClassifier(random_state=1)\n",
    "wine_dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This test confirms that you have created a DecisionTreeClassifier named wine_dt\n",
    "\n",
    "assert type(wine_dt) == DecisionTreeClassifier\n",
    "\n",
    "# This test confirms that you have set random_state to 1\n",
    "\n",
    "assert wine_dt.get_params()['random_state'] == 1\n",
    "\n",
    "# This test confirms that wine_dt has been fit\n",
    "\n",
    "sklearn.utils.validation.check_is_fitted(wine_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-55b417dc67abb7c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 4.3) Create an array `y_pred` generated by using `wine_dt` to make predictions for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CodeGrade step4.3\n",
    "# Replace None with appropriate code\n",
    "\n",
    "y_pred = wine_dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This test confirms that you have created an array-like object named y_pred\n",
    "\n",
    "assert type(np.asarray(y_pred)) == np.ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-536526728a8066e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 4.4) Create a numeric variable `wine_dt_acc` containing the accuracy score for your predictions. \n",
    "\n",
    "Hint: You can use the `sklearn.metrics` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-67272706fb08c3bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.0\n"
     ]
    }
   ],
   "source": [
    "# CodeGrade step4.4\n",
    "# Replace None with appropriate code\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "wine_dt_acc = accuracy_score(y_test,y_pred)\n",
    "print(round(wine_dt_acc,2)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This test confirms that you have created a numeric variable named wine_dt_acc\n",
    "\n",
    "assert isinstance(wine_dt_acc, Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87        33\n",
      "           1       0.81      0.88      0.85        34\n",
      "           2       0.91      0.95      0.93        22\n",
      "\n",
      "    accuracy                           0.88        89\n",
      "   macro avg       0.88      0.89      0.88        89\n",
      "weighted avg       0.88      0.88      0.88        89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "ct = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(ct).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-266fbd755dbbb4c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 4.5) Short Answer: Based on the accuracy score, does the model seem to be performing well or to have substantial performance issues? Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your answer here\n",
    "\n",
    "- Based on the accuracy score, I would say that the model is doing pretty well. Because without adding any hyperparamter/tunning the tree, we got a accuracy score of 88%, which is really good. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
